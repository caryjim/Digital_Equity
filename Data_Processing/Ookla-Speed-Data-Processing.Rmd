---
title: "Ookla Speedtest Data 2020 Processing"
author: "Cary K. Jim"
date: 
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_knit$set(root.dir = "D://Documents//R//Dissertation")
```
Data Source: Ookla on Github <https://github.com/teamookla/ookla-open-data>
```{r}
#Import libraries 
library(tidyverse)
```

# Import datasets 
These files are extracted from Ookla Open Data from AWS at US County Level with Census tigris package in R that was pre-processed in Oct 2020. The original R 
script that processed these files is Ookla_extract_county.R 

 Fixed speed result for all 4 quarters in 2020 from the raw file 
These files are between 80 - 93MB each quarter and takes some time to load. 
```{r}
fixed_Q1_2020 <- read.csv("./Datasets/OOKLA/2020/raw_fixed_01v1.csv", header = T)
fixed_Q2_2020 <- read.csv("./Datasets/OOKLA/2020/raw_fixed_02v1.csv", header = T)
fixed_Q3_2020 <- read.csv("./Datasets/OOKLA/2020/raw_fixed_03v1.csv", header = T)
fixed_Q4_2020 <- read.csv("./Datasets/OOKLA/2020/raw_fixed_04v1.csv", header = T)
```
The summary of County Level Data aggregated with download, upload, latency, devices_count, and test_county information. 

geoid is the FIPS code in Census for the county. We can use it as County ID. 
state_code is the corresponding number for the state. 
```{r}
head(fixed_Q1_2020)
```
I'm curious to know just one of the distribution in the speed data for Cuming
```{r}
fixed_Q1_2020 %>% filter(geoid == 31039) %>% ggplot(aes(avg_d_kbps/1000)) + geom_histogram() 
```
summary
```{r}
fixed_Q1_2020 %>% filter(geoid == 31039) %>% summarise(download_mean = mean(avg_d_kbps))
```
# Merge all 4 QT in 2020

Combine all 4 quarters into one year for 2020.
```{r}
fixed_2020 <- bind_rows(list(fixed_Q1_2020, fixed_Q2_2020, fixed_Q3_2020, 
                             fixed_Q4_2020), .id = "QT")
```
The merged raw data is about 339.1 MB, with 6834894 rows

View first 5 rows 
```{r}
head(fixed_2020)
```
View last 5 rows 
```{r}
tail(fixed_2020)
```

## Missing values in the raw data
```{r}
fixed_2020[!complete.cases(fixed_2020),]
```
There are 66 rows of missing values in the dataset. 

By looking at the state codes, the dataset included US territories. 
Guam and Northern Mariana Islands have county 69085, 69110, 69120, 69100, 66010

I'm going to remove the US territories first and then add state name to it.

## Drop U.S. Territories in the dataset
```{r}
fixed_2020 <- fixed_2020[!(fixed_2020$state_code == "69" | fixed_2020$state_code == "60"), ]
```
The rows has reduced to 6833755 after dropping either 69(MP) or 60(AS).

## Aggregate the county level data
```{r}
fixed_2020_Q <- fixed_2020 %>% group_by(QT, state_code, geoid, name) %>%
  summarise(avg_d_Mbps = mean(avg_d_kbps)/1000, 
            avg_u_Mbps = mean(avg_u_kbps)/1000,
            avg_latency = mean(avg_lat_ms),
            tests_count = sum(tests),
            devices_count = sum(devices)) 
```
The dataset is down to 12896 rows
```{r}
summary(fixed_2020_Q)
```
There are still missing values and after joining the state, we should have a 
better idea of where they are located. (NA's: 53)

## List of state code and abbreviation 
```{r}
list <-read.delim("./Utility/StateCodeList.txt", header = T, sep = " ")
list <- list[1:3]
list$FIPS <- as.numeric(list$FIPS)
```

Left-Join

```{r}
left_join(fixed_2020_Q, list, by = c("state_code" = "FIPS"))
```
## Export the Quarterly cleaned Fixed 2020 dataset 
```{r}
write.csv(fixed_2020_Q, "./Export/ookla/Yearly/Fixed_2020_Q.csv", row.names = F)
```



References:
- Use Census geographic data in R with tigris <https://walker-data.com/tigris-webinar/#1>
- Downloading Census blocks shapefile in R <https://rdrr.io/cran/tigris/man/blocks.html> 
- Filter and plot at the same time
<https://stackoverflow.com/questions/59273929/r-how-to-filter-data-with-a-list-of-arguments-to-produce-multiple-data-frames>
-Histogram in Tidyverse ggplot
<https://ggplot2.tidyverse.org/reference/geom_histogram.html>